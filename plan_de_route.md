[![MARNE ET GONDOIRE - LAGNY SUR MARNE | AtelierJL](https://tse3.mm.bing.net/th?id=OIP.4dUDEJlNFj_DOX926ov-kAHaC9\&pid=Api)](https://www.atelierjl.fr/copie-de-lyon-entree-est-zac-mermoz)

Voici une feuille de route d√©taill√©e au format Markdown pour le projet **Marne & Gondoire**, int√©grant le **Model Context Protocol (MCP)** afin de permettre √† vos agents IA d'interagir de mani√®re standardis√©e avec les outils m√©tiers.

---

# üìò Feuille de Route : Projet Marne & Gondoire avec MCP

## üéØ Objectif

Mettre en place une plateforme d'agents IA capable de :

* Scraper des donn√©es depuis des sites web.
* Ex√©cuter des requ√™tes SQL sur des bases de donn√©es internes.
* Lancer des workflows Airflow.
* G√©n√©rer des pr√©visions √† l'aide de mod√®les Prophet ou TFT.
* Le tout via le **Model Context Protocol (MCP)**, assurant une interop√©rabilit√© avec des LLMs comme GPT-4o, Claude ou Gemini.([Epsilon3D][1])

---

## üß± Structure du Projet

```
mg-platform/
‚îú‚îÄ‚îÄ mcp_server/
‚îÇ   ‚îú‚îÄ‚îÄ main.py         # Serveur FastAPI + SDK MCP
‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sql.py      # Fonction run_sql
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraper.py  # Fonction launch_scraper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ kpi.py      # Fonctions get_indicator, forecast_kpi
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ dags/               # Workflows Airflow
‚îú‚îÄ‚îÄ scrapers/           # Spiders Scrapy & Playwright
‚îú‚îÄ‚îÄ models/             # Mod√®les Prophet, TFT
‚îú‚îÄ‚îÄ clients/
‚îÇ   ‚îú‚îÄ‚îÄ openai_agent.py # Client MCP pour GPT-4o
‚îÇ   ‚îú‚îÄ‚îÄ claude_agent.py # Client MCP pour Claude 4
‚îÇ   ‚îî‚îÄ‚îÄ langgraph.py    # Agent ReAct LangChain
‚îî‚îÄ‚îÄ docker-compose.yml
```

---

## ‚öôÔ∏è Installation des D√©pendances

### 1. Cr√©er un environnement virtuel

```bash
python -m venv .venv
source .venv/bin/activate  # Sur Windows : .venv\Scripts\activate
```

### 2. Installer les paquets n√©cessaires

```bash
pip install "mcp[cli]" fastapi uvicorn[standard] sqlalchemy psycopg2-binary
```

> **Remarque** : Le SDK officiel MCP est disponible sous le nom `mcp` avec l'extra `[cli]` pour inclure les outils en ligne de commande.&#x20;

---

## üöÄ D√©veloppement du Serveur MCP

### 1. Exemple de serveur (`main.py`)

```python
from fastapi import FastAPI
from mcp.server import MCPServer, Tool, Arg, String, Integer
from tools.sql import run_sql
from tools.scraper import launch_scraper
from tools.kpi import get_indicator, forecast_kpi

app = FastAPI(title="MG Data MCP")

server = MCPServer(
    name="mg-data-mcp",
    description="Outils pour le pipeline Marne & Gondoire",
    version="0.1.0"
)

server.add_tool(
    Tool(
        name="run_sql",
        description="Ex√©cute une requ√™te SQL en lecture seule sur la base de donn√©es analytique",
        args=[Arg("query", String())],
        func=run_sql,
        permissions=["viewer", "editor"]
    )
)
server.add_tool(
    Tool(
        name="launch_scraper",
        description="Lance un spider Scrapy ou Playwright par nom",
        args=[Arg("spider", String()), Arg("url", String())],
        func=launch_scraper,
        permissions=["editor"]
    )
)
server.add_tool(
    Tool(
        name="get_indicator",
        description="Retourne la valeur d'un KPI pour une date donn√©e",
        args=[Arg("name", String()), Arg("date", String())],
        func=get_indicator,
        permissions=["viewer"]
    )
)
server.add_tool(
    Tool(
        name="forecast_kpi",
        description="Retourne une pr√©vision pour un KPI donn√©",
        args=[Arg("name", String()), Arg("horizon", Integer())],
        func=forecast_kpi,
        permissions=["viewer"]
    )
)

app.mount("/mcp", server.as_fastapi())
```

### 2. Lancer le serveur localement

```bash
uvicorn mcp_server.main:app --reload --port 8080
```

---

Bien s√ªr ! Voici ton plan de route **enrichi** avec les √©tapes demand√©es, dans un style coh√©rent avec le reste du document. Je t‚Äôint√®gre le bloc directement apr√®s la section ‚ÄúImpl√©mentation des Outils‚Äù, l√† o√π il s‚Äôint√®gre le plus naturellement.

---

## üõ†Ô∏è Impl√©mentation des Outils

*... (sections existantes inchang√©es)*

---

## üîç Analyse et Enrichissement des Fichiers de Donn√©es

### 1. Analyse des fichiers pour identifier les informations manquantes

Ajouter un outil (par exemple, `tools/analyze_files.py`) permettant de traiter diff√©rents formats de fichiers (`Excel`, `JSON`, CSV, etc.) pour :

* Parcourir les donn√©es,
* Rep√©rer les champs ou valeurs manquants,
* G√©n√©rer un rapport synth√©tique sur les donn√©es incompl√®tes.

### 2. Recherche et collecte d‚Äôinformations manquantes par scraping web

D√©velopper une fonction (exemple : `tools/fill_missing_data.py`) qui :

* Prend la liste des informations manquantes d√©tect√©es,
* Utilise des spiders Scrapy/Playwright ou des APIs publiques pour effectuer une recherche cibl√©e,
* Collecte et v√©rifie les donn√©es r√©cup√©r√©es.

### 3. G√©n√©ration d‚Äôun fichier enrichi

Mettre en place un outil qui :

* Fusionne les informations collect√©es avec le fichier source,
* Produit un nouveau fichier de donn√©es enrichi (Excel, JSON, etc.) et documente les modifications,
* Permet de t√©l√©charger ou d‚Äôarchiver ce nouveau fichier enrichi pour int√©gration dans le pipeline.

#### Exemple de structure possible pour l‚Äôoutil :

```python
def analyze_and_enrich_file(file_path: str) -> dict:
    missing_info = analyze_file_for_missing_data(file_path)
    found_data = scrape_missing_info(missing_info)
    enriched_file = merge_data(file_path, found_data)
    return {"enriched_file": enriched_file, "missing_report": missing_info}
```

---

**Tu pourras ainsi, pour chaque jeu de donn√©es, automatiser la compl√©tion et fiabiliser la collecte !**

Dis-moi si tu veux que j‚Äôint√®gre l‚Äôexemple de code d√©taill√© ou que je te r√©dige un README sp√©cifique pour cette nouvelle brique logicielle !





## üõ†Ô∏è Impl√©mentation des Outils

### 1. Ex√©cution de requ√™tes SQL (`tools/sql.py`)

```python
from sqlalchemy import create_engine, text

engine = create_engine("postgresql+psycopg2://mg:pwd@db:5432/analytics")

def run_sql(query: str) -> dict:
    with engine.begin() as conn:
        rows = conn.execute(text(query)).mappings().all()
    return {"rows": [dict(r) for r in rows]}
```

### 2. Lancer un scraper (`tools/scraper.py`)

```python
import subprocess

def launch_scraper(spider: str, url: str) -> dict:
    cmd = ["scrapy", "crawl", spider, "-a", f"start_url={url}"]
    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, text=True)
    return {"pid": proc.pid}
```

### 3. Gestion des KPIs (`tools/kpi.py`)

```python
import pandas as pd
from models.prophet import load_prophet

def get_indicator(name: str, date: str):
    # Impl√©mentation pour r√©cup√©rer la valeur du KPI
    pass

def forecast_kpi(name: str, horizon: int = 12):
    model = load_prophet(name)
    # Impl√©mentation pour g√©n√©rer la pr√©vision
    pass
```

---

## ü§ñ Int√©gration des Agents

### 1. OpenAI Agents SDK (`clients/openai_agent.py`)

```python
from openai import OpenAI
from openai.agents import Agent, MCPClient

mcp = MCPClient(url="http://localhost:8080/mcp")
agent = Agent(model="gpt-4o-mini", tools=[mcp])

response = agent.chat("Lance le scraper 'sitadel' sur https://... et dis-moi le PID.")
print(response.message)
```

### 2. Anthropic Claude (`clients/claude_agent.py`)

```python
from anthropic import Anthropic, MCPClient

anthropic = Anthropic()
mcp = MCPClient(url="http://localhost:8080/mcp")
chat = anthropic.claude.tools(client=mcp)

print(chat("run_sql: SELECT COUNT(*) FROM fact_permis"))
```

---

## üîê S√©curit√© et Authentification

* **En d√©veloppement local** : Utiliser un token Bearer simple dans l'en-t√™te `Authorization`.
* **En production** : Mettre en place OAuth2 ou mTLS pour s√©curiser les communications.

---

## üß™ Tests et CI/CD

* **Tests unitaires** : Utiliser `pytest` pour tester les fonctions expos√©es.
* **CI/CD** : Mettre en place des workflows avec GitHub Actions pour automatiser les tests et les d√©ploiements.

---

## ‚òÅÔ∏è D√©ploiement en Production

* **Serveur** : D√©ployer le serveur MCP sur un environnement de production s√©curis√©.
* **Nom de domaine** : Configurer un sous-domaine (ex. `mcp.mg-data.local`) avec un certificat TLS valide.
* **Scalabilit√©** : Envisager l'utilisation de solutions comme Cloudflare Workers pour une meilleure scalabilit√©.

---

## üìö Ressources Compl√©mentaires

* [Documentation officielle du SDK MCP](https://github.com/modelcontextprotocol/python-sdk)
* [Guide d'installation de FastMCP](https://pypi.org/project/fastmcp/)
* [Tutoriel pour construire un serveur MCP simple en Python](https://github.com/ruslanmv/Simple-MCP-Server-with-Python)

---
    
